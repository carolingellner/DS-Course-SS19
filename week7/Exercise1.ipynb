{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    def predict(self, X, k=1):\n",
    "        dists = self.get_distances(X)\n",
    "        n_test = dists.shape[0]\n",
    "        y_pred = np.zeros(n_test)\n",
    "        for i in range(n_test):\n",
    "            k_closest_y = []\n",
    "            labels = self.y_train[np.argsort(dists[i,:])].flatten()\n",
    "            # find k nearest lables\n",
    "            k_closest_y = labels[:k]\n",
    "            c = Counter(k_closest_y)\n",
    "            y_pred[i] = c.most_common(1)[0][0]\n",
    "        return(y_pred)\n",
    "\n",
    "    def get_distances(self, X):\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        \n",
    "        dot_prod = np.dot(X, self.X_train.T)\n",
    "        \n",
    "        sum_square_test = np.square(X).sum(axis = 1)\n",
    "        sum_square_test = np.expand_dims(sum_square_test,axis=1)\n",
    " \n",
    "        sum_square_train = np.square(self.X_train).sum(axis = 1)\n",
    "        sum_square_train = np.expand_dims(sum_square_train,axis=0)\n",
    "        \n",
    "        dists = np.sqrt(-2 * dot_prod + sum_square_train + sum_square_test)\n",
    "\n",
    "        return(dists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all names of files in the directory\n",
    "path = \"C:/Users/carol/DataSience/data/return-data/\"\n",
    "files = ([f for f in os.listdir(path) if f.endswith('.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    with open(path+file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            df_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to one dataframe\n",
    "dataframe = pd.DataFrame.from_dict(df_list)\n",
    "\n",
    "def normalize_mean(input):\n",
    "    return (input - input.mean()) / (input.max() - input.min())\n",
    "def rescaling (input):\n",
    "    return (input - input.min()) / (input.max() - input.min())\n",
    "def normalize(input):\n",
    "    return (input - input.mean()) / input.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.drop(axis=1,columns=['basket','returnLabel','transactionId','zipCode']),dataframe['returnLabel'], test_size=0.30,random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predicting the test data.\n",
      "Accuracy = 0.9620430107526882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = normalize(np.array(X_train))\n",
    "X_test = normalize(np.array(X_test))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "k = 5\n",
    "classifier = knn()\n",
    "classifier.train(X_train, y_train)\n",
    "pred = np.array(classifier.predict(X_test, k))\n",
    "\n",
    "\n",
    "print(\"Completed predicting the test data.\")\n",
    "#print(predictions)\n",
    "print('Accuracy = {}'.format(np.sum(y_test == pred)/len(y_test)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
